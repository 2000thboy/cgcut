# 视频素材混合检索系统方案设计

## 目标

实现三路混合检索系统，提升素材匹配准确度和多样性：

1. **CLIP 语义向量检索** - 视频内容语义理解
2. **文本标签检索** - 精确标签匹配
3. **文件名模糊检索** - 辅助定位

类似百度网盘智能搜索体验，自动混合多种检索结果。

## 当前问题分析

### 问题 1: 素材重复度高

- **现象**: 25 个镜头只匹配到 3 个不同视频循环使用
- **原因**:
  - CLIP 相似度阈值设为 0.1（过低）
  - 未对已匹配素材去重
  - 缺少多样性排序算法

### 问题 2: 匹配准确度低

- **现象**: 查询"办公室电脑焦虑"返回动漫镜头
- **原因**:
  - 仅依赖 CLIP 单一向量相似度
  - 标签过于宽泛（"办公室"标签覆盖 2677/2993 素材）
  - 缺少场景类型过滤

### 问题 3: 标签系统不完善

- **现状**:
  - 总素材: 2993 个
  - 去重后: 2579 个（414 个重复）
  - 标签分布极度不均：办公室(2677) >> 街道(257) > 夜晚(133)
- **缺陷**: 缺少层级分类、缺少情绪-场景组合标签

## 技术方案选型

### 方案对比

| 方案          | 优点                            | 缺点                 | 适用场景           |
| ------------- | ------------------------------- | -------------------- | ------------------ |
| **Milvus**    | 成熟稳定、十亿级性能、混合搜索  | 部署复杂、资源占用大 | 大规模生产环境     |
| **Qdrant**    | 轻量易用、Python 友好、本地部署 | 性能不如 Milvus      | 中小规模、快速迭代 |
| **Chroma**    | 超简单集成、自带 Embedding      | 功能相对简单         | 原型验证           |
| **当前 JSON** | 零依赖、已有实现                | 线性搜索慢、功能受限 | 当前阶段 MVP       |

### 推荐方案: **Qdrant 增量迁移**

**原因**:

1. **轻量**: Docker 单容器部署，资源占用小
2. **Python 友好**: 官方 Python SDK 完善
3. **混合检索**: 支持向量+过滤器组合查询
4. **可回退**: 保留现有 JSON 方案作为 fallback
5. **成熟**: 开源项目 7.8k stars，文档完善

## 实现路线图

### 阶段 1: 优化当前 CLIP 匹配（立即实施）

**目标**: 不引入新依赖，快速提升匹配质量

**改进措施**:

1. **提升相似度阈值**

   ```python
   # 当前: threshold=0.1 (几乎无过滤)
   # 改为: threshold=0.25 (保证基本语义相关)
   ```

2. **添加多样性去重**

   ```python
   # 跟踪已使用素材
   used_shots = set()

   # 优先选择未使用素材
   for candidate in candidates:
       if candidate.shotId not in used_shots:
           used_shots.add(candidate.shotId)
           return candidate
   ```

3. **增加标签过滤**

   ```python
   # 构建场景类型映射
   SCENE_TYPE_TAGS = {
       "办公室": ["办公室", "室内场景"],
       "街道": ["街道", "室外场景", "城市"],
       "自然": ["自然风景", "室外场景"]
   }

   # 根据scene字段过滤标签
   filter_tags = SCENE_TYPE_TAGS.get(block.scene, [])
   ```

4. **优化查询构建**
   ```python
   # 当前: 直接用全文查询
   # 改为: 提取关键实体+情绪组合
   query = f"{场景} {主要动作} {情绪}氛围"
   ```

**预期效果**:

- 相似度阈值提升 → 减少无关匹配
- 多样性去重 → 避免重复使用同一素材
- 标签过滤 → 场景类型准确

### 阶段 2: 完善标签体系（1-2 天）

**目标**: 建立结构化、层级化的标签系统

**标签重构方案**:

```python
# 新的标签结构
TAGS_SCHEMA = {
    "scene_type": ["室内", "室外", "自然"],
    "location": ["办公室", "街道", "房间", "公园"],
    "shot_type": ["特写", "近景", "中景", "全景", "远景"],
    "subject": ["人物", "面部", "手部", "群体", "无人"],
    "action": ["行走", "奔跑", "静坐", "对话", "工作"],
    "emotion": ["紧张", "平静", "恐惧", "快乐"],
    "lighting": ["明亮", "昏暗", "自然光", "人工光"],
    "time": ["白天", "夜晚", "黄昏", "清晨"]
}

# 组合标签生成
def generate_composite_tags(metadata):
    tags = []
    # 场景+情绪组合
    if metadata.scene and metadata.emotion:
        tags.append(f"{metadata.scene}_{metadata.emotion}")
    # 景别+主体组合
    if metadata.shot_type and metadata.subject:
        tags.append(f"{metadata.shot_type}_{metadata.subject}")
    return tags
```

**重标签策略**:

1. 使用 LLM 批量重打标（GLM-4-Flash 便宜快速）
2. 保留原 CLIP 标签作为辅助
3. 生成组合标签增加匹配精度

### 阶段 3: 集成 Qdrant 混合检索（2-3 天）

**架构设计**:

```
Frontend (React)
    ↓
AssetMatchingService
    ↓
    ├─→ QdrantService (向量检索)
    │   ├─ 语义向量搜索
    │   └─ 标签过滤
    ↓
    ├─→ TextSearchService (全文检索)
    │   └─ 文件名模糊匹配
    ↓
    └─→ HybridRanker (结果融合)
        └─ 多路加权排序
```

**实现步骤**:

1. **安装 Qdrant**

   ```bash
   # Docker部署
   docker run -p 6333:6333 qdrant/qdrant

   # Python客户端
   pip install qdrant-client
   ```

2. **数据迁移**

   ```python
   from qdrant_client import QdrantClient
   from qdrant_client.models import Distance, VectorParams

   client = QdrantClient("localhost", port=6333)

   # 创建集合
   client.create_collection(
       collection_name="video_clips",
       vectors_config=VectorParams(
           size=512,  # CLIP ViT-B/32 维度
           distance=Distance.COSINE
       )
   )

   # 批量导入现有数据
   from clip_results.json import load
   for item in load('clip_results.json'):
       client.upsert(
           collection_name="video_clips",
           points=[{
               "id": item['shotId'],
               "vector": item['clipMetadata']['embeddings'],
               "payload": {
                   "label": item['label'],
                   "tags": item['clipMetadata']['tags'],
                   "filePath": item['filePath'],
                   "emotions": item['clipMetadata']['emotions']
               }
           }]
       )
   ```

3. **混合检索实现**

   ```python
   def hybrid_search(query_text, scene_filter=None, top_k=10):
       # 1. CLIP向量检索
       query_vector = clip_model.encode_text(query_text)

       # 2. 构建过滤条件
       filter_conditions = None
       if scene_filter:
           filter_conditions = {
               "must": [
                   {"key": "tags", "match": {"any": scene_filter}}
               ]
           }

       # 3. 向量搜索 + 过滤
       vector_results = client.search(
           collection_name="video_clips",
           query_vector=query_vector,
           query_filter=filter_conditions,
           limit=top_k * 2  # 过采样
       )

       # 4. 文件名文本匹配（辅助）
       text_results = fuzzy_search_filename(query_text)

       # 5. 结果融合排序
       final_results = merge_and_rerank(
           vector_results,
           text_results,
           weights={'vector': 0.7, 'text': 0.3}
       )

       return final_results[:top_k]
   ```

4. **多样性重排序**
   ```python
   def diversify_results(results, alpha=0.5):
       """MMR (Maximal Marginal Relevance) 多样性排序"""
       selected = []
       candidates = results.copy()

       while len(selected) < len(results) and candidates:
           if not selected:
               # 第一个选择最相关
               selected.append(candidates.pop(0))
           else:
               # 平衡相关性和多样性
               scores = []
               for cand in candidates:
                   relevance = cand.similarity
                   diversity = min(
                       1 - cosine_sim(cand, s)
                       for s in selected
                   )
                   mmr_score = alpha * relevance + (1-alpha) * diversity
                   scores.append((mmr_score, cand))

               # 选择MMR最高的
               scores.sort(reverse=True)
               selected.append(scores[0][1])
               candidates.remove(scores[0][1])

       return selected
   ```

**预期效果**:

- 向量检索速度: <50ms (vs 当前 JSON 线性扫描 ~500ms)
- 混合检索准确率: 提升 30%+
- 多样性: MMR 算法保证前 10 结果差异化

## 实施计划

### 本次提交: 阶段 1 优化（立即）

- [x] 移除测试剧本确认弹窗
- [x] 提升 CLIP 相似度阈值到 0.27（平衡精度和召回）
- [x] 添加素材去重逻辑（usedShotIds + deduplicateCandidates）
- [x] 优化查询构建（提取关键词，移除景别/时长/情绪标记）
- [x] 测试验证匹配效果（2026-01-16 验证通过）

### 下次迭代: 阶段 2 标签重构（最小版本已完成）

- [x] 分析标签分布问题（"办公室"标签覆盖89%素材）
- [x] 基于文件名关键词的标签修复脚本（fix_tags_simple.py）
- [x] 更新 clip_results.json（修复419个素材，新增动漫场景/面部特写等标签）
- [x] 同步到Qdrant并验证标签过滤功能
- [ ] （可选）设计完整标签Schema + LLM批量重打标

### 未来规划: 阶段 3 Qdrant 集成（已完成）

- [x] Docker 部署 Qdrant（运行在 127.0.0.1:6333）
- [x] 数据迁移脚本（migrate_to_qdrant.py）
- [x] 实现混合检索 API（qdrant_search.py + clip_server.py）
- [x] 集成到前端（assetMatchingService.ts + clipService.ts）
- [x] 性能基准测试（2026-01-16 验证通过，MMR多样性算法正常）

## 参考资料

- [Qdrant 官方文档](https://qdrant.org.cn/)
- [CLIP-Retrieval 项目](https://github.com/rom1504/clip-retrieval)
- [混合检索最佳实践](https://milvus.io/docs/v2.5.x/hybrid_search_with_milvus.md)
- [MMR 多样性排序算法](https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf)
